#!/usr/bin/env python3
"""
Test script for explainability features (LIME, SHAP, Grad-CAM)
"""

import os
from models import (
    load_yolo_model, detect_all_cells_comprehensive, 
    generate_comprehensive_explainability,
    LIME_AVAILABLE, SHAP_AVAILABLE, GRADCAM_AVAILABLE
)

def test_explainability_features():
    """Test all explainability features"""
    
    print("ğŸ”¬ Testing AI Explainability Features")
    print("=" * 50)
    
    # Check availability
    print("ğŸ“‹ Checking explainability method availability:")
    print(f"   ğŸ” LIME: {'âœ… Available' if LIME_AVAILABLE else 'âŒ Not available'}")
    print(f"   ğŸ“Š SHAP: {'âœ… Available' if SHAP_AVAILABLE else 'âŒ Not available'}")
    print(f"   ğŸ¯ Grad-CAM: {'âœ… Available' if GRADCAM_AVAILABLE else 'âŒ Not available'}")
    
    if not any([LIME_AVAILABLE, SHAP_AVAILABLE, GRADCAM_AVAILABLE]):
        print("\nâŒ No explainability methods available!")
        print("Install required packages:")
        print("pip install lime shap grad-cam pytorch-grad-cam")
        return False
    
    # Use sample image
    sample_image = "dataset/train/images/BloodImage_00001_jpg.rf.1a3206b15602db1d97193162a50bd001.jpg"
    
    if not os.path.exists(sample_image):
        print(f"âŒ Sample image not found: {sample_image}")
        return False
    
    print(f"\nğŸ“· Using sample image: {os.path.basename(sample_image)}")
    
    # Load model
    print("\nğŸ“¥ Loading detection model...")
    model = load_yolo_model('yolo11n.pt')
    
    if model is None:
        print("âŒ Failed to load model")
        return False
    
    print("âœ… Model loaded successfully")
    
    # Run basic detection first
    print("\nğŸ” Running blood cell detection...")
    detection_results = detect_all_cells_comprehensive(model, sample_image, confidence_threshold=0.01)
    
    if not detection_results:
        print("âŒ Detection failed")
        return False
    
    stats = detection_results['stats']
    print(f"âœ… Detection complete: {stats['total_cells_detected']} cells found")
    
    # Generate comprehensive explainability
    print("\nğŸš€ Generating comprehensive explainability analysis...")
    explainability_results = generate_comprehensive_explainability(
        sample_image, 
        model, 
        output_dir="explainability_test_results"
    )
    
    if explainability_results:
        print(f"\nğŸ‰ Explainability analysis completed!")
        print(f"ğŸ“ Results saved in: explainability_test_results/")
        
        for method, path in explainability_results.items():
            if os.path.exists(path):
                print(f"   âœ… {method.upper()}: {path}")
            else:
                print(f"   âŒ {method.upper()}: Failed")
        
        return True
    else:
        print("âŒ Explainability analysis failed")
        return False

if __name__ == "__main__":
    success = test_explainability_features()
    if success:
        print("\nâœ… All explainability tests passed!")
        print("ğŸ¯ The system now includes LIME, SHAP, and Grad-CAM explanations!")
    else:
        print("\nâŒ Explainability tests failed!")